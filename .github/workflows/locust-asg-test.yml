name: ASG Replication Load Test

on:
  workflow_dispatch:

jobs:
  load-test:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Locust
        run: pip install locust 

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Create Locustfile
        run: |
          cat <<EOF > locustfile.py
          import logging
          from locust import HttpUser, task, between, events

          logging.basicConfig(level=logging.INFO)

          class ASGLoadTest(HttpUser):
              wait_time = between(1, 5)

              @task(3)
              def access_homepage(self):
                  with self.client.get("/", catch_response=True) as response:
                      if response.status_code == 200:
                          response.success()
                      elif response.status_code in [502, 503, 504]:
                          response.failure(f"ALB Error: {response.status_code}")
                      else:
                          response.failure(f"Error: {response.status_code}")

              @task(1)
              def cpu_intensive_task(self):
                  self.client.get("/heavy-compute")

          @events.test_stop.add_listener
          def on_test_stop(environment, **kwargs):
              print("\nSCENARIO FINISHED\n")
          EOF

      - name: Scenario 1 - Baseline (100 Users)
        env:
          ALB_URL: ${{ secrets.ALB_URL }}
        run: |
          echo ">>> Monitoring: Starting Baseline..."
          locust -f locustfile.py --host "$ALB_URL" --headless -u 200 -r 5 --run-time 1m --html "baseline.html" --only-summary || true
          echo ">>> Current Running Instances:"
          aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --query "length(Reservations[*].Instances[])" --output text

      - name: Scenario 2 - Stress Test (500 Users)
        if: always()
        env:
          ALB_URL: ${{ secrets.ALB_URL }}
        run: |
          echo ">>> Monitoring: Starting Stress Test..."
          locust -f locustfile.py --host "$ALB_URL" --headless -u 600 -r 15 --run-time 1m --html "stress.html" --only-summary || true
          echo ">>> Checking for replication..."
          aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --query "length(Reservations[*].Instances[])" --output text

      - name: Cooldown & Provisioning Wait
        if: always()
        run: |
          echo "Waiting 2 minutes for ASG to spin up new instances..."
          sleep 120
          echo ">>> Instance count after cooldown:"
          aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --query "length(Reservations[*].Instances[])" --output text

      - name: Scenario 3 - Peak Load (1000 Users)
        if: always()
        env:
          ALB_URL: ${{ secrets.ALB_URL }}
        run: |
          echo ">>> Monitoring: Starting Peak Load..."
          locust -f locustfile.py --host "$ALB_URL" --headless -u 1200 -r 30 --run-time 1m --html "peak.html" --only-summary || true
          echo ">>> Final Running Instances:"
          aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --query "length(Reservations[*].Instances[])" --output text

      - name: Upload Test Reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: locust-asg-reports
          path: "*.html"
